单机处理大数据问题  
需求：有一个非常大的文本文件，里面有很多行，只有两行是一样的，它们出现在未知的位置。需要查找它们。
单机，而且可用的内存很少，只有几十兆  
思路：哈希code ？很有可能会有哈希冲突，但是已经过滤掉了绝大部分了。再对哈希值相同的数据进行比较，即可

<h1>各种版本之间的差异</h1> （第一节课 1小时之后的视频有）
Hadoop项目：  
1.X版本中有的：  
Hadoop Common  
HDFS  
Hadoop MapReduce  
2.X版本中有
YARN
CDH企业现在用的5.X的比较多，因为集成的版本相对比较稳定，如现在集成的Hadoop是2.6
但6.X集成的hadoop就是3.X了。

***
<h1>理论知识点</h1>
<h5>•存储模型</h5>
<h5>•架构设计</h5>
<h5>•角色功能</h5>
<h5>•元数据持久化</h5>
<h5>•安全模式</h5>
<h5>•副本放置策略</h5>
<h5>•读写流程</h5>
<h5>•安全策略</h5>

***
<h2>存储模型</h2>
PPT内容：《02hadoop-hdfs.pptx》
分布式文件系统那么多
为什么hadoop项目中还要开发一个hdfs文件系统？  

存储模型  
文件线性按字节切割成块(block)，具有offset，id  
HDFS会把大的文件散开，可以支持分治。很多计算可以发送到计算节点，移动数据比移动计算快，数据向计算移动。
这是理论，但是实际上是如何分工的？
先举个例子，如果有10个人，找到班里的不同的同学存储数据，存完之后N个月过来取，他们怎么记得自己的数据是存在哪个同学的笔记本里边了呢？
那么就让10个同学的笔记本电脑存储数据，其中一个人的电脑用来记账，负责记录数据是存储在谁的电脑里的  
文件与文件的block大小可以不一样  
一个文件除最后一个block，其他block大小一致  
block的大小依据硬件的I/O特性调整  
block被分散存放在集群的节点中，具有location  
Block具有副本(replication)，没有主从概念，副本不能出现在同一个节点  
副本是满足可靠性和性能的关键  
文件上传可以指定block大小和副本数，上传后只能修改副本数  
一次写入多次读取，不支持修改  
支持追加数据  

<h1>架构设计</h1>
HDFS是一个主从(Master/Slaves)架构  
物理架构设计中，HDFS是主从架构。主从、主备。主从，master-slaves，两个人都是工作，而且有通信，互相协作。主备，高可用，一个工作，一个备用。  
由一个NameNode和一些DataNode组成   
nn就是主，dn就是从  
面向文件包含：文件数据(data)和文件元数据(metadata)
文件：声音视频或者其他的文件
win：文件属性
linux或者其他：元数据
NameNode负责存储和管理文件元数据，并维护了一个层次型的文件目录树
win:盘符
linux:目录树
hdfs:目录树，且不是物理操作的目录树
DataNode负责存储文件数据(block块)，并提供block的读写
dn，存储数据。
DataNode与NameNode维持心跳，并汇报自己持有的block信息
Client和NameNode交互文件元数据和DataNode交互文件block数据
client和nn和dn交互不同的东西
最主要的就是nn,dn,client
linux:分区
win:盘符
win
软件 必须从G盘加载一个文件 conf xml
linux
/a /b /c /d /e /f /g
mount /g -> dist:G分区  /b->dist:B分区
软件 必须从/g读取文件，如果没有/g, 可以创建/g，且可以挂在任何一个分区上（有可能是g分区也有可能不是g分区)，但win如果没有g盘符，就会出错。
linux相对于win的好处：软件具备了移动性。程序具备移动性
hdfs也维护了目录树结构，和linux一样，虚拟目录树结构。物理磁盘像win。
目录树对硬件分区做了解耦。
下图为hdfs架构图
<img src="./pic/pic1.png" width="873" height="604"/>

<h2>角色功能</h2>
<h4>NameNode</h4>  
<font color='red'>完全基于内存存储文件元数据、目录结构、文件block的映射  
需要持久化方案保证数据可靠性  
提供副本放置策略  
</font>
<h4>DataNode</h4>  
<font color='red'>
基于本地磁盘存储block(文件的形式)  
并保存block的校验和数据保证block的可靠性  </font>
校验和：哈希，做文件的校验用的。DN存两个东西：1）数据块本身；2）校验和的那笔数据
<font color='red'>与NameNode保持心跳，汇报block列表状态  </font>


记住：角色即进程
NN即一个JVM，内部维护一个目录树结构
集群里有DN。DN描述的是集群的数量。
客户端和NN交互元数据。
NN：path(唯一，这是目录树文件结构的特征)
副本数，副本的位置。

NN是唯一的主
阿里建议集群不要超过5000台
NN完全基于内存存储元数据。（不是基于磁盘）
内存寻址速度是磁盘的10W倍
NN的内存持久化方案和REDIS的内存持久化方案不同

客户端把文件给DN，由DN来存储文件。所以其实文件不是由hdfs来存的，HDFS就是管理映射，就是来了数据，存到哪，做个记账。

